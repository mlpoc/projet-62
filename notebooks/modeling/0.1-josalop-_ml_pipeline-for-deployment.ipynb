{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Model Pipeline: Wrapping up for Deployment\n",
    "\n",
    "\n",
    "Here, we will summarise, the key pieces of code, that we need to take forward, for this particular project, to put our model in production.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josal\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# to handle datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# to divide train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# feature scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# to build the models\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# to evaluate the models\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# to persist the model and the scaler\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# to visualise al the columns in the dataframe\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the seed\n",
    "\n",
    "\n",
    "Important note **Always set the seeds**.\n",
    "\n",
    "Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "We need the training data to train our model in the production environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(329275, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_postal</th>\n",
       "      <th>date_mutation</th>\n",
       "      <th>id_parcelle</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>nature_culture</th>\n",
       "      <th>nom_commune</th>\n",
       "      <th>nombre_lots</th>\n",
       "      <th>nombre_pieces_principales</th>\n",
       "      <th>numero_disposition</th>\n",
       "      <th>surface_reelle_bati</th>\n",
       "      <th>surface_terrain</th>\n",
       "      <th>type_local</th>\n",
       "      <th>valeur_fonciere</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9800.0</td>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>092630000A0991</td>\n",
       "      <td>42.936027</td>\n",
       "      <td>0.931099</td>\n",
       "      <td>jardins</td>\n",
       "      <td>Saint-Jean-du-Castillonnais</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>245.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>78450.0</td>\n",
       "      <td>2019-12-13</td>\n",
       "      <td>78674000ZL0016</td>\n",
       "      <td>48.840698</td>\n",
       "      <td>2.000984</td>\n",
       "      <td>prés</td>\n",
       "      <td>Villepreux</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4050.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1007200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>78440.0</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>783170000B0236</td>\n",
       "      <td>49.051101</td>\n",
       "      <td>1.843135</td>\n",
       "      <td>taillis sous futaie</td>\n",
       "      <td>Jambville</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56465.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>320000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>44550.0</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>44103000AB0121</td>\n",
       "      <td>47.327899</td>\n",
       "      <td>-2.153218</td>\n",
       "      <td>sols</td>\n",
       "      <td>Montoir-de-Bretagne</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>Local industriel. commercial ou assimilé</td>\n",
       "      <td>243420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>2019-04-20</td>\n",
       "      <td>11069000AE0372</td>\n",
       "      <td>43.218986</td>\n",
       "      <td>2.346464</td>\n",
       "      <td>sols</td>\n",
       "      <td>Carcassonne</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>Maison</td>\n",
       "      <td>131500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code_postal date_mutation     id_parcelle   latitude  longitude  \\\n",
       "0       9800.0    2019-09-06  092630000A0991  42.936027   0.931099   \n",
       "1      78450.0    2019-12-13  78674000ZL0016  48.840698   2.000984   \n",
       "2      78440.0    2019-03-05  783170000B0236  49.051101   1.843135   \n",
       "3      44550.0    2019-10-30  44103000AB0121  47.327899  -2.153218   \n",
       "4      11000.0    2019-04-20  11069000AE0372  43.218986   2.346464   \n",
       "\n",
       "        nature_culture                  nom_commune  nombre_lots  \\\n",
       "0              jardins  Saint-Jean-du-Castillonnais            0   \n",
       "1                 prés                   Villepreux            0   \n",
       "2  taillis sous futaie                    Jambville            0   \n",
       "3                 sols          Montoir-de-Bretagne            0   \n",
       "4                 sols                  Carcassonne            0   \n",
       "\n",
       "   nombre_pieces_principales  numero_disposition  surface_reelle_bati  \\\n",
       "0                        NaN                   1                  NaN   \n",
       "1                        NaN                   1                  NaN   \n",
       "2                        NaN                   1                  NaN   \n",
       "3                        0.0                   1                 60.0   \n",
       "4                        5.0                   1                106.0   \n",
       "\n",
       "   surface_terrain                                type_local  valeur_fonciere  \n",
       "0            245.0                                       NaN         167220.0  \n",
       "1           4050.0                                       NaN        1007200.0  \n",
       "2          56465.0                                       NaN         320000.0  \n",
       "3             98.0  Local industriel. commercial ou assimilé         243420.0  \n",
       "4           1223.0                                    Maison         131500.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv('../../data/interim/raw_useful_ftrs.csv')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 329275 entries, 0 to 329274\n",
      "Data columns (total 14 columns):\n",
      "code_postal                  329143 non-null float64\n",
      "date_mutation                329275 non-null object\n",
      "id_parcelle                  329275 non-null object\n",
      "latitude                     322415 non-null float64\n",
      "longitude                    322415 non-null float64\n",
      "nature_culture               243611 non-null object\n",
      "nom_commune                  329275 non-null object\n",
      "nombre_lots                  329275 non-null int64\n",
      "nombre_pieces_principales    180225 non-null float64\n",
      "numero_disposition           329275 non-null int64\n",
      "surface_reelle_bati          141350 non-null float64\n",
      "surface_terrain              243602 non-null float64\n",
      "type_local                   180434 non-null object\n",
      "valeur_fonciere              329275 non-null float64\n",
      "dtypes: float64(7), int64(2), object(5)\n",
      "memory usage: 35.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recode code postal as object (This should be done on EDA Preproc Script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 329275 entries, 0 to 329274\n",
      "Data columns (total 14 columns):\n",
      "code_postal                  329143 non-null object\n",
      "date_mutation                329275 non-null object\n",
      "id_parcelle                  329275 non-null object\n",
      "latitude                     322415 non-null float64\n",
      "longitude                    322415 non-null float64\n",
      "nature_culture               243611 non-null object\n",
      "nom_commune                  329275 non-null object\n",
      "nombre_lots                  329275 non-null int64\n",
      "nombre_pieces_principales    180225 non-null float64\n",
      "numero_disposition           329275 non-null int64\n",
      "surface_reelle_bati          141350 non-null float64\n",
      "surface_terrain              243602 non-null float64\n",
      "type_local                   180434 non-null object\n",
      "valeur_fonciere              329275 non-null float64\n",
      "dtypes: float64(6), int64(2), object(6)\n",
      "memory usage: 35.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(329275, 14)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[:,'code_postal'] = data.loc[:,'code_postal'].astype('object')\n",
    "data.info()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "adresse_code_voie               False\n",
       "adresse_nom_voie                False\n",
       "adresse_numero                  False\n",
       "adresse_suffixe                 False\n",
       "ancien_code_commune             False\n",
       "ancien_id_parcelle              False\n",
       "ancien_nom_commune              False\n",
       "code_commune                    False\n",
       "code_departement                False\n",
       "code_nature_culture             False\n",
       "code_nature_culture_speciale    False\n",
       "code_postal                      True\n",
       "code_type_local                 False\n",
       "date_mutation                    True\n",
       "id_mutation                     False\n",
       "id_parcelle                      True\n",
       "latitude                         True\n",
       "longitude                        True\n",
       "lot1_numero                     False\n",
       "lot1_surface_carrez             False\n",
       "lot2_numero                     False\n",
       "lot2_surface_carrez             False\n",
       "lot3_numero                     False\n",
       "lot3_surface_carrez             False\n",
       "lot4_numero                     False\n",
       "lot4_surface_carrez             False\n",
       "lot5_numero                     False\n",
       "lot5_surface_carrez             False\n",
       "nature_culture                   True\n",
       "nature_culture_speciale         False\n",
       "nature_mutation                 False\n",
       "nom_commune                      True\n",
       "nombre_lots                      True\n",
       "nombre_pieces_principales        True\n",
       "numero_disposition               True\n",
       "numero_volume                   False\n",
       "surface_reelle_bati              True\n",
       "surface_terrain                  True\n",
       "type_local                       True\n",
       "valeur_fonciere                 False\n",
       "Name: use_ftr, dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset tags on features to use\n",
    "features_csv= pd.read_csv('../../data/interim/features_to_use_summary.csv', index_col=0)\n",
    "print(features_csv.shape)\n",
    "features_csv.use_ftr.head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate dataset into train and test\n",
    "\n",
    "Before beginning to engineer our features, it is important to separate our data intro training and testing set. This is to avoid over-fitting. There is an element of randomness in dividing the dataset, so remember to set the seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((296347, 14), (32928, 14))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's separate into train and test set\n",
    "# Remember to seet the seed (random_state for this sklearn function)\n",
    "# \n",
    "X_train, X_test, y_train, y_test = train_test_split(data, data.valeur_fonciere,\n",
    "                                                    test_size=0.1,\n",
    "                                                    random_state=SEED) # we are setting the seed here\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected features\n",
    "\n",
    "Remember that we will deploy our model utilising only a subset of features, the most predictive ones. This is to make simpler models, so that we build simpler code for deployment. We will tell you more about this in coming lectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  13\n"
     ]
    }
   ],
   "source": [
    "# load selected features\n",
    "features = list(features_csv.loc[features_csv.use_ftr==True, :].index)\n",
    "...\n",
    "features\n",
    "\n",
    "print('Number of features: ', len(features))\n",
    "# Remember that add extra ftrs additional feature engineering step into production as p.ex distance_to_big_city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values\n",
    "\n",
    "For categorical variables, we will fill missing information by adding an additional category: \"missing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make a list of the categorical variables that contain missing values\n",
    "vars_with_na = [var for var in features if X_train[var].isnull().sum()>1 and X_train[var].dtypes=='O']\n",
    "\n",
    "# print the variable name and the percentage of missing values\n",
    "# for var in vars_with_na:\n",
    "#     print(var, np.round(X_train[var].isnull().mean(), 3),  ' % missing values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still categorical variables with NA for the final model, so we need to include this piece of feature engineering logic in the deployment pipeline to input those NA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code_postal       0\n",
       "nature_culture    0\n",
       "type_local        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next functio can go  in the feature engineering notebook:\n",
    "\n",
    "# function to replace NA in categorical variables\n",
    "def fill_categorical_na(df, var_list):\n",
    "    X = df.copy()\n",
    "    X[var_list] = df[var_list].fillna('Missing')\n",
    "    return X\n",
    "\n",
    "# replace missing values with new label: \"Missing\"\n",
    "X_train = fill_categorical_na(X_train, vars_with_na)\n",
    "X_test = fill_categorical_na(X_test, vars_with_na)\n",
    "\n",
    "# check that we have no missing information in the engineered variables\n",
    "X_train[vars_with_na].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For numerical variables, we are going to add an additional variable capturing the missing information, and then replace the missing information in the original variable by the mode, or most frequent value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latitude 0.021  % missing values\n",
      "longitude 0.021  % missing values\n",
      "nombre_pieces_principales 0.452  % missing values\n",
      "surface_reelle_bati 0.571  % missing values\n",
      "surface_terrain 0.261  % missing values\n"
     ]
    }
   ],
   "source": [
    "# make a list of the numerical variables that contain missing values\n",
    "vars_with_na = [var for var in features if X_train[var].isnull().sum()>1 and X_train[var].dtypes!='O']\n",
    "vars_with_na\n",
    "# print the variable name and the percentage of missing values\n",
    "for var in vars_with_na:\n",
    "    print(var, np.round(X_train[var].isnull().mean(), 3),  ' % missing values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems however that surfacer_reelle_bati and surface_trrain should be inputed to zero while others can be inputed to median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_with_na_at_zero = ['surface_reelle_bati', 'surface_terrain']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important: persisting the mean value for NA imputation\n",
    "\n",
    "As you will see in future sections, one of the key pieces of deploying the model is \"Model Validation\". Model validation refers to corroborating that the deployed model and the model built during research, are identical. The entire pipeline needs to produce identical results.\n",
    "\n",
    "Therefore, in order to check at the end of the process that the feature engineering pipelines are identical, we will save -we will persist-, the mean value of the variable, so that we can use it at the end, to corroborate our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latitude                     0\n",
       "longitude                    0\n",
       "nombre_pieces_principales    0\n",
       "surface_reelle_bati          0\n",
       "surface_terrain              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace the missing values\n",
    "\n",
    "mean_var_dict = {}\n",
    "\n",
    "for var in vars_with_na:\n",
    "    \n",
    "    # calculate the mode\n",
    "    mode_val = X_train[var].mode()[0]\n",
    "    \n",
    "    # we persist the mean in the dictionary\n",
    "    mean_var_dict[var] = mode_val\n",
    "    \n",
    "    # train\n",
    "    # note  that the additional binary variable was not selected, so we don't need this step any more\n",
    "    #X_train[var+'_na'] = np.where(X_train[var].isnull(), 1, 0)\n",
    "    X_train[var].fillna(mode_val, inplace=True)\n",
    "    \n",
    "    # test\n",
    "    # note  that the additional binary variable was not selected, so we don't need this step any more\n",
    "    #X_test[var+'_na'] = np.where(X_test[var].isnull(), 1, 0)\n",
    "    X_test[var].fillna(mode_val, inplace=True)\n",
    "\n",
    "# we save the dictionary for later\n",
    "np.save('../../models/mean_var_dict.npy', mean_var_dict)\n",
    "\n",
    "# check that we have no more missing values in the engineered variables\n",
    "X_train[vars_with_na].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal variables\n",
    "\n",
    "We can add here some temporal EDA features, such as date transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create the temporal var \"elapsed years\"\n",
    "# def elapsed_years(df, var):\n",
    "#     # capture difference between year variable and year the house was sold\n",
    "#     df[var] = df['YrSold'] - df[var]\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = elapsed_years(X_train, 'YearRemodAdd')\n",
    "# X_test = elapsed_years(X_test, 'YearRemodAdd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical variables\n",
    "\n",
    "We will log transform some numerical variables that do not contain zeros in order to get a more Gaussian-like distribution. This tends to help Linear machine learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['latitude', 'longitude', 'nombre_lots', 'nombre_pieces_principales',\n",
       "       'numero_disposition', 'surface_reelle_bati', 'surface_terrain',\n",
       "       'valeur_fonciere'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num_ftrs = X_train.select_dtypes('number').columns\n",
    "num_ftrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftrs_to_log_transf = ['valeur_fonciere']\n",
    "for var in ftrs_to_log_transf:\n",
    "    X_train[var] = np.log1p(X_train[var])\n",
    "    X_test[var]= np.log1p(X_test[var])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical variables\n",
    "\n",
    "We do have categorical variables in our final model. First, we will remove those categories within variables that are present in less than 1% of the observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['code_postal',\n",
       " 'date_mutation',\n",
       " 'id_parcelle',\n",
       " 'nature_culture',\n",
       " 'nom_commune',\n",
       " 'type_local']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's capture the categorical variables first\n",
    "cat_vars = [var for var in features if X_train[var].dtype == 'O']\n",
    "cat_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important: persisting the frequent labels\n",
    "\n",
    "As you will see in future sections, one of the key pieces of deploying the model is \"Model Validation\". Model validation refers to corroborating that the deployed model and the model built during research, are identical. The entire pipeline needs to produce identical results.\n",
    "\n",
    "Therefore, in order to check at the end of the process, that the feature engineering pipelines are identical, we will save -we will persist-, the list of frequent labels per variable, so that we can use it at the end, to corroborate our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_frequent_labels(df, var, rare_perc):\n",
    "    # finds the labels that are shared by more than a certain % of the houses in the dataset\n",
    "    df = df.copy()\n",
    "    tmp = df.groupby(var)['valeur_fonciere'].count() / len(df)\n",
    "    return tmp[tmp>rare_perc].index\n",
    "\n",
    "frequent_labels_dict = {}\n",
    "\n",
    "for var in cat_vars:\n",
    "    frequent_ls = find_frequent_labels(X_train, var, 0.01)\n",
    "    \n",
    "    # we save the list in a dictionary\n",
    "    frequent_labels_dict[var] = frequent_ls\n",
    "    \n",
    "    X_train[var] = np.where(X_train[var].isin(frequent_ls), X_train[var], 'Rare')\n",
    "    X_test[var] = np.where(X_test[var].isin(frequent_ls), X_test[var], 'Rare')\n",
    "    \n",
    "# now we save the dictionary\n",
    "np.save('../../models/FrequentLabels.npy', frequent_labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code_postal': Index([], dtype='object', name='code_postal'),\n",
       " 'date_mutation': Index([], dtype='object', name='date_mutation'),\n",
       " 'id_parcelle': Index([], dtype='object', name='id_parcelle'),\n",
       " 'nature_culture': Index(['Missing', 'futaies résineuses', 'jardins', 'landes', 'prés', 'sols',\n",
       "        'taillis simples', 'terrains a bâtir', 'terrains d'agrément', 'terres',\n",
       "        'vignes'],\n",
       "       dtype='object', name='nature_culture'),\n",
       " 'nom_commune': Index([], dtype='object', name='nom_commune'),\n",
       " 'type_local': Index(['Appartement', 'Dépendance', 'Local industriel. commercial ou assimilé',\n",
       "        'Maison', 'Missing'],\n",
       "       dtype='object', name='type_local')}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_labels_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to transform the strings of these variables into numbers. We will do it so that we capture the monotonic relationship between the label and the target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will assign discrete values to the strings of the variables, \n",
    "# so that the smaller value corresponds to the smaller mean of target\n",
    "\n",
    "def replace_categories(train, test, var, target):\n",
    "    ordered_labels = train.groupby([var])[target].mean().sort_values().index\n",
    "    ordinal_label = {k:i for i, k in enumerate(ordered_labels, 0)} \n",
    "    train[var] = train[var].map(ordinal_label)\n",
    "    test[var] = test[var].map(ordinal_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for var in cat_vars:\n",
    "    replace_categories(X_train, X_test, var, 'valeur_fonciere')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check absence of na\n",
    "[var for var in features if X_train[var].isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check absence of na\n",
    "[var for var in features if X_test[var].isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "\n",
    "For use in linear models, features need to be either scaled or normalised. In the next section, I will scale features between the min and max values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture the target\n",
    "y_train = X_train['valeur_fonciere']\n",
    "y_test = X_test['valeur_fonciere']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../models/scaler.pkl']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit scaler\n",
    "scaler = MinMaxScaler() # create an instance\n",
    "scaler.fit(X_train[features]) #  fit  the scaler to the train set for later use\n",
    "\n",
    "# we persist the model for future use\n",
    "joblib.dump(scaler, '../../models/scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the train and test set, and add on the Id and SalePrice variables\n",
    "X_train = pd.DataFrame(scaler.transform(X_train[features]), columns=features)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test[features]), columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_postal</th>\n",
       "      <th>date_mutation</th>\n",
       "      <th>id_parcelle</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>nature_culture</th>\n",
       "      <th>nom_commune</th>\n",
       "      <th>nombre_lots</th>\n",
       "      <th>nombre_pieces_principales</th>\n",
       "      <th>numero_disposition</th>\n",
       "      <th>surface_reelle_bati</th>\n",
       "      <th>surface_terrain</th>\n",
       "      <th>type_local</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.970994</td>\n",
       "      <td>0.550094</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.896280</td>\n",
       "      <td>0.591264</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.941102</td>\n",
       "      <td>0.552015</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.012155</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.947205</td>\n",
       "      <td>0.517275</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.914319</td>\n",
       "      <td>0.526196</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code_postal  date_mutation  id_parcelle  latitude  longitude  \\\n",
       "0          0.0            0.0          0.0  0.970994   0.550094   \n",
       "1          0.0            0.0          0.0  0.896280   0.591264   \n",
       "2          0.0            0.0          0.0  0.941102   0.552015   \n",
       "3          0.0            0.0          0.0  0.947205   0.517275   \n",
       "4          0.0            0.0          0.0  0.914319   0.526196   \n",
       "\n",
       "   nature_culture  nom_commune  nombre_lots  nombre_pieces_principales  \\\n",
       "0        0.909091          0.0     0.005714                   0.000000   \n",
       "1        0.909091          0.0     0.005714                   0.000000   \n",
       "2        0.272727          0.0     0.000000                   0.000000   \n",
       "3        0.636364          0.0     0.000000                   0.000000   \n",
       "4        0.818182          0.0     0.000000                   0.121212   \n",
       "\n",
       "   numero_disposition  surface_reelle_bati  surface_terrain  type_local  \n",
       "0                 0.0             0.000367         0.000726        0.25  \n",
       "1                 0.0             0.000367         0.000726        0.25  \n",
       "2                 0.0             0.000367         0.012155        0.00  \n",
       "3                 0.0             0.000367         0.002244        0.00  \n",
       "4                 0.0             0.000423         0.000842        0.50  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296347"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.isnull().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../models/model.pkl']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "models = { 'lasso': Lasso(alpha=0.005, random_state=SEED)           # REMEMBER to set the random_state / seed\n",
    "          ,'treeReg': DecisionTreeRegressor(random_state=SEED)\n",
    "         }\n",
    "\n",
    "\n",
    "model = models['treeReg']\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# we persist the model for future use\n",
    "joblib.dump(model, '../../models/model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mse: 62821172688.4176\n",
      "Train rmse: 250641.5222751761\n",
      "\n",
      "Test mse: 14871396475009.244\n",
      "Test rmse: 3856344.9631755254\n",
      "\n",
      "Average property price:  132000.9999999999\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model:\n",
    "# remember that we log transformed the output (SalePrice) in our feature engineering notebook / lecture.\n",
    "\n",
    "# In order to get the true performance of the Lasso\n",
    "# we need to transform both the target and the predictions\n",
    "# back to the original house prices values.\n",
    "# \n",
    "# We will evaluate performance using the mean squared error and the\n",
    "# root of the mean squared error\n",
    "\n",
    "pred = model.predict(X_train)\n",
    "print('Train mse: {}'.format(mean_squared_error(np.exp(y_train), np.exp(pred))))\n",
    "print('Train rmse: {}'.format(sqrt(mean_squared_error(np.exp(y_train), np.exp(pred)))))\n",
    "print()\n",
    "pred = model.predict(X_test)\n",
    "print('Test mse: {}'.format(mean_squared_error(np.exp(y_test), np.exp(pred))))\n",
    "print('Test rmse: {}'.format(sqrt(mean_squared_error(np.exp(y_test), np.exp(pred)))))\n",
    "print()\n",
    "print('Average property price: ', np.exp(y_train).median())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "583px",
    "left": "0px",
    "right": "1324px",
    "top": "107px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
