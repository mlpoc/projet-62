{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "md"
   },
   "outputs": [],
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "## Prix de Vente des ProprietÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import quickda\n",
    "\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "import seaborn as sns\n",
    "import quickda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Set Fix Parame\n",
    "    \n",
    "SEED = 1234 # Seed for random  number geneartors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "md"
   },
   "outputs": [],
   "source": [
    "### Load  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#ROOT_PATH = os.path.abspath(os.path.dirname(__file__))\n",
    "data_folder = '../../data/raw/'\n",
    "\n",
    "\n",
    "filenames = [  \n",
    "               #'dvf_2018.gz',\n",
    "              'dvf_2019.gz'\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    " # Util Fn to read write out a data sample from origina raw data files\n",
    " def pd_read_save(filename, sample_size, output_path):\n",
    " #    n = sum(1 for line in open(filename, errors = \"ignore\")) - 1 #number of records in file (excludes header)\n",
    " #    print(\"total rows\")\n",
    " #    s = sample_size #desired sample sizfre\n",
    " #    skip = sorted(np.random.random_integers(1,n+1,n-s)) #the 0-indexed header will not be included in the skip list\n",
    "     df = pd.read_csv(filename, error_bad_lines = False) #, skiprows=skip\n",
    "     df_sample =  df.sample(sample_size, random_state = SEED)\n",
    "     df_sample.to_csv(output_path, sep = \";\", index = False)\n",
    "     print('Writing file of shape: ', df_sample.shape)\n",
    "     return df\n",
    "\n",
    "\n",
    " for f in filenames:\n",
    "     data = data_folder + f\n",
    "     print(data_folder  +'samples/'+f.split('.')[0]  +'_sample.csv.gz')\n",
    "     pd_read_save( data, sample_size=400000, output_path = data_folder  +'samples/'+f.split('.')[0]  +'_sample.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Read saved data samples\n",
    "    \n",
    "dsets = {} #f.split('.')[0]: pd.DataFrame() for f in filenames\n",
    "\n",
    "for f in filenames:\n",
    "    base_name = f.split('.')[0]\n",
    "    dsets[base_name] = pd.read_csv(  data_folder  + 'samples/' + base_name + '_sample.csv.gz'\n",
    "                                   , error_bad_lines = False, sep = ';'\n",
    "                                   )\n",
    "    print(base_name, dsets[base_name].shape)\n",
    "\n",
    "\n",
    "\n",
    "%%md \n",
    "#### Merge the Data Sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Merge the data sets\n",
    "\n",
    "data_in = pd.concat([dsets[d] for d in dsets.keys()])\n",
    "print(data_in.shape) \n",
    "print(data_in.tail(2).T)\n",
    "\n",
    "# Initial pre Analysis showed that  there are many duplicated rows.\n",
    "data_in.drop_duplicates(inplace=True)\n",
    "print(data_in.shape) \n",
    "\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "md"
   },
   "outputs": [],
   "source": [
    "#### Explore Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_in.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Get Proportion of Null values on Columns\n",
    "\n",
    "#nulls_df = pd.DataFrame( {'Nulls': data_in.isnull().sum().values\n",
    "#                        , 'Ptj':data_in.isnull().sum() /  data_in.shape[0]\n",
    "#                        }\n",
    "#                       )\n",
    "#print(nulls_df)\n",
    "\n",
    "\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "md"
   },
   "outputs": [],
   "source": [
    "###Data Summary\n",
    "# Summary of the Row Data Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "from quickda.explore_data import *\n",
    "from quickda.clean_data import *\n",
    "from quickda.explore_numeric import *\n",
    "from quickda.explore_categoric import *\n",
    "from quickda.explore_numeric_categoric import *\n",
    "from quickda.explore_time_series import *\n",
    "\n",
    "\n",
    "summary = explore(data_in, method=\"summarize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "summary  # Display Raw Data Summary\n",
    "\n",
    "#summary\n",
    "\n",
    "# ========================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "md"
   },
   "outputs": [],
   "source": [
    "#### Assign Features on Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "%md Useful FtrsDrop Reason: They can not have missing values\n",
    "#valeur_fonciere           (target cant have nulls)\n",
    "\n",
    "\n",
    "%md High null pct ftrs\n",
    "\n",
    "#adresse_suffixe                 0.958\n",
    "#ancien_code_commune             0.991\n",
    "#ancien_id_parcelle              0.999\n",
    "#ancien_nom_commune              0.991\n",
    "#code_nature_culture_speciale    0.954\n",
    "#code_type_local                 0.476\n",
    "#lot1_numero                     0.687\n",
    "#lot1_surface_carrez             0.912\n",
    "#lot2_numero                     0.935\n",
    "#lot2_surface_carrez             0.979\n",
    "#lot3_numero                     0.989\n",
    "#lot3_surface_carrez             0.998\n",
    "#lot4_numero                     0.996\n",
    "#lot4_surface_carrez             0.999\n",
    "#lot5_numero                     0.998\n",
    "#lot5_surface_carrez             1.000\n",
    "#nature_culture_speciale         0.954\n",
    "#numero_volume                   0.997\n",
    "\n",
    "\n",
    "%md Useful FtrsRedundant Features\n",
    "#                               dtypes   count  null_sum  null_pct  nunique\n",
    "#ancien_code_commune           float64    7004    778519     0.991      532   \n",
    "#code_commune                   object  785523         0     0.000    31251   \n",
    "#code_departement               object  785523         0     0.000       97   \n",
    "#code_nature_culture            object  535959    249564     0.318       27   \n",
    "#code_nature_culture_speciale   object   35761    749762     0.954      113   \n",
    "#code_type_local               float64  411728    373795     0.476        4  \n",
    "\n",
    "\n",
    "%md Useful Ftrs\n",
    "#surface_reelle_bati           118074  0.590370  NaN 0\n",
    "#nombre_pieces_principales      93279  0.466395  NaN 0\n",
    "#nature_culture                 62293  0.311465  NaN \"N/A\"\n",
    "#code_type_local NAN  \"N/A\"\n",
    "#longitude                       4048  0.020240  k-neighb estim\n",
    "#latitude                        4048  0.020240  k-neighb estim\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "md"
   },
   "outputs": [],
   "source": [
    "#### Setting Unuseful featues for analysis   Using above summary results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "# Assigning Features to differet categorie types"
   },
   "outputs": [],
   "source": [
    "\n",
    "unuseful_ftrs = ['id_mutation', 'adresse_nom_voie', 'adresse_numero']\n",
    "\n",
    "useful_high_ptc_ftrs = [  'adresse_numero'\n",
    "                        , 'nombre_pieces_principales'\n",
    "                        , 'type_local'\n",
    "                        , 'surface_reelle_bati' \n",
    "                        , 'type_local'\n",
    "                        ]\n",
    "\n",
    "#Un inputable high nulls ftrs\n",
    "ftrs_high_null_ptc = [f for f in summary.loc[summary.null_pct > 0.40,:].index  if f not in useful_high_ptc_ftrs]\n",
    "#summary.loc[ftrs_high_null_ptc, 'null_pct']\n",
    "\n",
    "useful_code_ftrs =  [\n",
    "                     'code_postal'\n",
    "                    ]\n",
    "\n",
    "redundant_ftrs = [c for c in summary.index if 'code' in c and c not in useful_code_ftrs]\n",
    "redundant_ftrs\n",
    "\n",
    "\n",
    "unuseful_ftrs += sorted(list(set(ftrs_high_null_ptc).union(set(redundant_ftrs))))\n",
    "unuseful_ftrs\n",
    "\n",
    "\n",
    "ftrs = list(sorted([f for f in data_in.columns if f not in unuseful_ftrs])) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Inspect left useful ftrs\n",
    "smmry4 = ['dtypes', 'count', 'null_pct', 'nunique']\n",
    "summary.loc[ftrs, smmry4]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "%%md \n",
    "### Set useful Feature Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Set useful Feature Groups\n",
    "\n",
    "ftrs = list(sorted([f for f in data_in.columns if f not in unuseful_ftrs]))\n",
    "target = 'valeur_fonciere'\n",
    "ftrs.remove(target)\n",
    "\n",
    "num_ftrs = list(summary.loc[summary.index.isin(ftrs) & (summary['dtypes'] != 'object'),:].index)\n",
    "num_ftrs = [f for f in num_ftrs if f not in ['code_postal']] # Remove wrogly assigned num ftrs and target\n",
    "data_in.loc[:,'code_postal'] = data_in.loc[:,'code_postal'].astype('str')\n",
    "\n",
    "summary.loc[num_ftrs,smmry4]\n",
    "\n",
    "date_ftrs = ['date_mutation']\n",
    "\n",
    "cat_ftrs = list(summary.loc[summary.index.isin(ftrs)\n",
    "                 & (summary['dtypes'] == 'object')\n",
    "                 & (summary['nunique'] > 2 )\n",
    "                 ,:].index\n",
    "                )\n",
    "cat_ftrs.append('code_postal')\n",
    "bool_ftrs = []\n",
    "\n",
    "# Assert all columns have bee assigned to a ftr class\n",
    "all_solumns_assigned = len(set(data_in.columns).symmetric_difference(\n",
    "        set(unuseful_ftrs + num_ftrs + cat_ftrs + date_ftrs + bool_ftrs + [target])))==0\n",
    "assert(all_solumns_assigned)\n",
    "\n",
    "\n",
    "data_in2 = data_in.loc[:, [target] + ftrs ]\n",
    "\n",
    "\n",
    "for dt in [date_ftrs, num_ftrs, cat_ftrs]:\n",
    "    print(summary.loc[dt, smmry4])\n",
    "\n",
    "data_in2.tail(1).T\n",
    "\n",
    "# =============================================================================\n",
    "#% md \n",
    "'''\n",
    "Check Duplicates\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "md It seems like duplicates are sales with id_parcelle"
   },
   "outputs": [],
   "source": [
    "# and valeur_fonciere when they are same more than once "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore number of duplicated id parcells, This, inf fact should be a dropped field\n",
    "by_id_parcells = data_in.groupby('id_parcelle')\n",
    "#by_id_parcells.agg({'id_mutation': 'count'}).id_mutation.value_counts()#.plot.bar() #head()\n",
    "by_parcell_mutations = by_id_parcells.agg({'id_mutation': 'count'}).reset_index()\n",
    "# print(by_parcell_mutations.head())\n",
    "\n",
    "nuni_ue_mutations_parcels = by_parcell_mutations.loc[\n",
    "                                    by_parcell_mutations.id_mutation>1,'id_parcelle'] #filter parcels wit 2 or more mutations\n",
    "\n",
    "nuni_ue = (data_in.loc[data_in.id_parcelle.isin(nuni_ue_mutations_parcels.values),:]\n",
    "                    .sort_values(by=['id_parcelle']\n",
    "                    )\n",
    "          )\n",
    "nuni_ue.tail(4).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop duplicate properties\n",
    "id_ftrs = ['id_parcelle'\n",
    "           #, 'id_mutation', 'date_mutation', 'numero_disposition', 'nature_mutation'\n",
    "           , 'valeur_fonciere'\n",
    "           ]\n",
    "data = data_in2.drop_duplicates(subset=id_ftrs, keep='last')\n",
    "print(data.shape)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "%%md #### Explore Target Feature\n",
    "# First Plotting target_value in thousands to facilitate visualization\n",
    "\n",
    "\n",
    "%%md Original target values are very left skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Add sale value in thousands for easiest management\n",
    "# Now plot log of target value\n",
    "df_plot = data.sample(10000, random_state=SEED)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "(df_plot.valeur_fonciere/1000).plot.hist(ax = ax, bins = 10)\n",
    "#sns.histplot(df_plot.valeur_fonciere/1000, ax=ax,  kde=False)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "%%md Applying log transformations gives a very centered distribution\n",
    "# There is, however a small separated group of very low valuew which can, maybe be inspected to see if they are outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Measure proportiob of extreme (by eyesight they are over 2 million value 20)\n",
    "extreme_vals_ptj = data.loc[data.valeur_fonc_mil>1500].shape[0] / data.shape[0] *100\n",
    "print(\"Fount extreme values ptj: {:.2f}%\".format(extreme_vals_ptj)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add the scaled target value to use\n",
    "\n",
    "data['valeur_fonciere_log'] = np.log1p(data['valeur_fonciere'])\n",
    "\n",
    "# Now plot log of target value\n",
    "df_plot = data.sample(10000, random_state=SEED)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "sns.histplot(np.log1p(df_plot.valeur_fonciere_log.values), ax=ax,  kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "md # Potentian outlier vals are sell values under 90 and are approx 1% of data"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "outlier_thr =  np.expm1(4.5)\n",
    "print('Outlier threshold:', outlier_thr)\n",
    "print(  data.loc[data['valeur_fonciere_log']<4.5,:].shape\n",
    "      , data.loc[data['valeur_fonciere']<outlier_thr,:].shape)\n",
    "\n",
    "print('Prop of outliers: {:.2f}'.format(\n",
    "        data.loc[data['valeur_fonciere_log']<4.5,:].shape[0]/ data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Log distrib is centered but there is a small cluster on values close to 0. Let's explore it\n",
    "\n",
    "identity_ftrs = ['id_parcelle', 'latitude', 'longitude',  'nature_culture']\n",
    "atypic_low = data.loc[data.valeur_fonciere_log<1, :].sort_values(by=['valeur_fonciere', 'id_parcelle'])\n",
    "#atypic_low.show()\n",
    "atypic_low.shape[0] / data.shape[0]\n",
    "\n",
    "atypic_low.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "data.loc[data.valeur_fonciere_log<1, :].sort_values(by=['id_parcelle', 'valeur_fonciere']).head(100).nature_culture.value_counts()\n",
    "\n",
    "\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "md ### Exploratoty Analysis"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# =============================================================================\n",
    "%%md ####  Categorical features vs Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "# Set low cardinality features subset\n",
    "summary.loc[summary.index.isin(cat_ftrs),:]\n",
    "\n",
    "cat_ftrs_nunique_low = summary.loc[  summary.index.isin(cat_ftrs) & (summary['nunique'] < 28)\n",
    "                                       , summary.columns[0:5]].index\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "md Plot each categorical value vs Target"
   },
   "outputs": [],
   "source": [
    "# We see that for nature_mutation and culture_nature categories seem to influence target\n",
    "# while type_local ones don't seem to have an impact. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot each categorical value vs Target\n",
    "for f in cat_ftrs_nunique_low:\n",
    "    data.loc[:,f] = data[f].astype('category')\n",
    "    fig, ax = plt.subplots(figsize = (14,10))\n",
    "    for cat in data.loc[:,f].cat.categories:\n",
    "#        print(f,cat)\n",
    "        # Select the category type\n",
    "        subset = data.loc[data[f] == cat, :]\n",
    "        \n",
    "        # Density plot of Energy Star scores\n",
    "        sns.kdeplot(subset['valeur_fonciere_log'].dropna(),\n",
    "                   label = cat, shade = False, alpha = 0.8);\n",
    "    \n",
    "    # label the plot\n",
    "    ax.legend()\n",
    "    plt.xlabel('Value by {} ftr'.format(f), size = 20); plt.ylabel('Density', size = 20); \n",
    "    plt.title('Density Plot of {} Scores by {}'.format('valeur_foncier', f), size = 28);\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "#### md Inspect Numeric Features"
   },
   "outputs": [],
   "source": [
    "    \n",
    "# By inspecting continuous features against the target we found next discoveries:\n",
    "# 1. Nombre de lots, surface reel batie et nombre de pieces principales semblent avoir\n",
    "# une influence dans la valeur fonciere. 2. Longitude et Latitude aussi semblen avoir une influence\n",
    "# cÃ©pendant il existe un  petit cluster separÃ© des autres dans lon[5,15] et lat [-60, -50]. Possibly delete these\n",
    "# and not make predictions for outside Euope Continent France Territories\n",
    "# Other numeric features dont seem to have an important contribution on value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "for f in num_ftrs:\n",
    "    data_plt = data.sample(1000, )\n",
    "    sns.jointplot(x=f, y='valeur_fonciere_log', data=data_plt, kind=\"reg\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#% On the other hand, features are not highly correlated to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#eda_num(data.loc[:,num_ftrs], method='correlation')\n",
    "    \n",
    "corr =  data.loc[:,num_ftrs].corr(method = 'pearson')\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "sns.heatmap(corr, annot=True, cmap=\"Greens\")\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "md Predictive Capacity of Features"
   },
   "outputs": [],
   "source": [
    "# Finally we inspect the predictive capacity of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "pred_mtx = eda_numcat(data, x=None, y=None, method=\"pps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "md ### Export Summary of features to use"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Make sunmary of all original colunns and left rows\n",
    "summary_out = explore(data_in.loc[data.index,:], method=\"summarize\")\n",
    "summary_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_out.loc[ftrs, smmry4]\n",
    "summary.loc[unuseful_ftrs, smmry4]\n",
    "summary['use_ftr'] = [True if f in ftrs else False for f in summary.index]\n",
    "summary.loc[ftrs,smmry4]\n",
    "#summary['use_ftr']\n",
    "summary.to_csv('../../data/interim/features_to_use_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
